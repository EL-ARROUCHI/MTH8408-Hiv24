{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MTH8408 : Méthodes d'optimisation et contrôle optimal\n",
    " ## Laboratoire 2: Optimisation sans contraintes\n",
    "Tangi Migot et Paul Raynaud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réaliser par : `Taha El Arrouchi`\n",
    "Matricule : `2194007`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1: Newton avec recherche linéaire - amélioration du code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `c:\\Users\\Admin\\.github\\MTH8408-Hiv24`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Admin\\.github\\MTH8408-Hiv24\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Admin\\.github\\MTH8408-Hiv24\\Manifest.toml`"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Admin\\.github\\MTH8408-Hiv24\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Admin\\.github\\MTH8408-Hiv24\\Manifest.toml`"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Admin\\.github\\MTH8408-Hiv24\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Admin\\.github\\MTH8408-Hiv24\\Manifest.toml`"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Admin\\.github\\MTH8408-Hiv24\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Admin\\.github\\MTH8408-Hiv24\\Manifest.toml`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `C:\\Users\\Admin\\.github\\MTH8408-Hiv24\\Project.toml`\n",
      "  \u001b[90m[54578032] \u001b[39mADNLPModels v0.7.0\n",
      "  \u001b[90m[f6369f11] \u001b[39mForwardDiff v0.10.36\n",
      "  \u001b[90m[b6b21f68] \u001b[39mIpopt v1.6.1\n",
      "  \u001b[90m[4076af6c] \u001b[39mJuMP v1.19.0\n",
      "  \u001b[90m[40e66cde] \u001b[39mLDLFactorizations v0.10.1\n",
      "  \u001b[90m[a4795742] \u001b[39mNLPModels v0.20.0\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[5049e819] \u001b[39mOptimizationProblems v0.5.0\n",
      "\u001b[36m\u001b[1mInfo\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m have new versions available and may be upgradable."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\") #Accède au fichier Project.toml\n",
    "Pkg.instantiate()\n",
    "Pkg.add(\"LDLFactorizations\")\n",
    "Pkg.add(\"OptimizationProblems\")\n",
    "Pkg.add(\"Ipopt\")\n",
    "Pkg.add(\"JuMP\")\n",
    "Pkg.status()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ADNLPModels, LinearAlgebra, NLPModels, Printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "armijo (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Amélioration possibles: return also the value of f\n",
    "function armijo(xk, dk, fk, gk, f)\n",
    "  slope = dot(gk, dk) #doit être <0\n",
    "  t = 1.0\n",
    "  while f(xk + t * dk) > fk + 1.0e-4 * t * slope\n",
    "    t /= 1.5\n",
    "  end\n",
    "  return t\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newton_armijo (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function newton_armijo(nlp, x0; verbose::Bool = true)\n",
    "    F(x) = obj(nlp, x)\n",
    "    g(x) = grad(nlp, x)\n",
    "    H(x) = hess(nlp, x)\n",
    "    xk  = x0\n",
    "    fk  = F(xk)\n",
    "    gk = g(xk)\n",
    "    gnorm = gnorm0 = norm(gk)\n",
    "    k = 0\n",
    "    verbose  && @printf \"%2s %9s %9s\\n\" \"k\" \"fk\" \"||∇f(x)||\"\n",
    "    verbose  && @printf \"%2d %9.2e %9.1e\\n\" k fk gnorm\n",
    "    evaluations = 0 # Apres 1000 évaluation, on arrête\n",
    "    t_0=time() # temps de départ, on arrête après 60s\n",
    "    while gnorm > 1.0e-6 + 1.0e-6 * gnorm0 && k < 100\n",
    "      Hk = H(xk)\n",
    "      dk = - Hk \\ gk\n",
    "      slope = dot(dk, gk)\n",
    "      λ = 0.0\n",
    "      itt = 0 # Apres 5 ittération, on passe\n",
    "      while slope ≥ -1.0e-4 * norm(dk) * gnorm\n",
    "        λ = max(1.0e-3, 10 * λ)\n",
    "        dk = - ((Hk + λ * I ) \\ gk)\n",
    "        slope = dot(dk, gk)\n",
    "        itt += 1\n",
    "        println(\"Ittération numéro:\", itt)\n",
    "        if itt == 5\n",
    "          dk = -gk\n",
    "          break\n",
    "        end\n",
    "      end\n",
    "      t = armijo(xk, dk, fk, gk, F)\n",
    "      xk += t * dk\n",
    "      fk = F(xk)\n",
    "      if fk < -1e15\n",
    "        println(\"le problème est non-bornée inférieurement.\")\n",
    "        break\n",
    "      end\n",
    "      gk = g(xk)\n",
    "      gnorm = norm(gk)\n",
    "      k += 1\n",
    "      verbose && @printf \"%2d %9.2e %9.1e %7.1e\\n\" k fk gnorm t\n",
    "\n",
    "      evaluations += neval_obj(nlp)\n",
    "      t_f = time() - t_0\n",
    "      println(\"Nombre d'évaluation: \", evaluations,\" Temps d'évaluation: \", t_f)\n",
    "      if evaluations >= 1000\n",
    "        println(\"Nombre maximal d'évaluations de fonctions est atteint.\")\n",
    "        break\n",
    "      end\n",
    "    if t_f >= 60\n",
    "        println(\"Limite de temps atteinte.\")\n",
    "        break\n",
    "    end\n",
    "    end\n",
    "    return xk\n",
    "  end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1: Newton avec recherche linéaire - amélioration du code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " k        fk ||∇f(x)||\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0  1.00e+00   4.5e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1  5.08e-02   8.4e-01 1.0e+00\n",
      "Nombre d'évaluation: 3 Temps d'évaluation: 1.503000020980835\n",
      " 2  4.73e-04   7.6e-02 1.0e+00\n",
      "Nombre d'évaluation: 8 Temps d'évaluation: 1.5370001792907715\n",
      " 3  6.97e-08   9.1e-04 1.0e+00\n",
      "Nombre d'évaluation: 15 Temps d'évaluation: 1.5370001792907715\n",
      " 4  1.62e-15   1.4e-07 1.0e+00\n",
      "Nombre d'évaluation: 24 Temps d'évaluation: 1.5370001792907715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 2.323057366509693e-8\n",
       " 2.3230573665124037e-8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test\n",
    "f(x) = x[1]^2 * (2*x[1] - 3) - 6*x[1]*x[2] * (x[1] - x[2] - 1)\n",
    "x0=[.5, .5]\n",
    "nlp = ADNLPModel(f, x0)\n",
    "\n",
    "newton_armijo(nlp, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2: LDLt-Newton avec recherche linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant modifier la méthode de Newton vu précédemment pour utiliser un package qui s'occupe de calculer une factorisation de la matrice hessienne tel que:\n",
    "$$\n",
    "\\nabla^2 f(x) = LDL^T.\n",
    "$$\n",
    "Ce type de factorisation n'est possible que si la matrice hessienne est définie positive, dans le cas contraire on a besoin de régularisé le système comme dans l'exercice précédent.\n",
    "\n",
    "Pour résoudre le système linéaire en utilisant cette factorisation, on va utiliser le package [`LDLFactorizations`](https://github.com/JuliaSmoothOptimizers/LDLFactorizations.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LDLFactorizations, LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utiliser de la correction pour calculer la direction de descente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newton_ldlt_armijo (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solution: modifier le calcul de la direction avec LDLFactorizations\n",
    "function newton_ldlt_armijo(nlp, x0; verbose::Bool = true)\n",
    "  xk  = x0\n",
    "  fk  = obj(nlp, xk)\n",
    "  gk = grad(nlp, xk)\n",
    "  gnorm = gnorm0 = norm(gk)\n",
    "  k = 0\n",
    "  verbose && @printf \"%2s %9s %9s\\n\" \"k\" \"fk\" \"||∇f(x)||\"\n",
    "  verbose && @printf \"%2d %9.2e %9.1e\\n\" k fk gnorm\n",
    "  while gnorm > 1.0e-6 + 1.0e-6 * gnorm0 && k < 100 && fk > -1e15\n",
    "    Hk = Symmetric(triu(hess(nlp, xk)), :U)\n",
    "    Sk = ldl_analyze(Hk)\n",
    "    ldl_factorize!(Hk, Sk)\n",
    "    Sk.d=abs.(Sk.d)\n",
    "    dk = - Sk \\ gk\n",
    "    slope = dot(dk, gk)\n",
    "    t = armijo(xk, dk, fk, gk, x -> obj(nlp, x))\n",
    "    xk += t * dk\n",
    "    fk = obj(nlp, xk)\n",
    "    gk = grad(nlp, xk)\n",
    "    gnorm = norm(gk)\n",
    "    k += 1\n",
    "    verbose && @printf \"%2d %9.2e %9.1e %7.1e \\n\" k fk gnorm t\n",
    "  end\n",
    "  return xk\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " k        fk ||∇f(x)||\n",
      " 0  1.00e+00   4.5e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1  5.08e-02   8.4e-01 1.0e+00 \n",
      " 2  4.73e-04   7.6e-02 1.0e+00 \n",
      " 3  6.97e-08   9.1e-04 1.0e+00 \n",
      " 4  1.62e-15   1.4e-07 1.0e+00 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 2.323057366856638e-8\n",
       " 2.3230573665124037e-8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test\n",
    "f(x) = x[1]^2 * (2*x[1] - 3) - 6*x[1]*x[2] * (x[1] - x[2] - 1)\n",
    "nlp = ADNLPModel(f, zeros(2))\n",
    "\n",
    "newton_ldlt_armijo(nlp, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3: Méthode quasi-Newton: BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bfgs_quasi_newton_armijo (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solution: copier-coller votre newton_armijo ici et modifier le calcul de la direction avec la méthode de BFGS inverse skip.\n",
    "function bfgs_quasi_newton_armijo(nlp, x0; verbose::Bool = true)\n",
    "  xk = x0\n",
    "  fk  = obj(nlp, xk)\n",
    "  gk = grad(nlp, xk)\n",
    "  gnorm = gnorm0 = norm(gk)\n",
    "  Hk=zeros(2,2,100)\n",
    "  yk=zeros(2,100) \n",
    "  rhok=zeros(1,100) \n",
    "  # J'utiliserai un pas de 1/10 pour les x\n",
    "  sk=ones(2)*1/10\n",
    "  for i in 1:100\n",
    "  yk[:,i]=grad(nlp, i*sk)-grad(nlp, (i-1)*sk)\n",
    "  rhok[i] = 1 / (transpose(yk[:, i]) * sk)\n",
    "  end\n",
    "  #Hk(:,:,1) c'est H_0 \n",
    "  Hk[:,:,1]=(I-rhok[1]*sk*transpose(yk[:,1]))*(I-rhok[1]*yk[:,1]*transpose(sk))+rhok[1]*sk*transpose(sk)\n",
    "  #Hk(:,:,1)=(transpose(yk[:,1])*sk)/(transpose(yk[:,1])*yk[:,1])*I\n",
    "  for i in 2:100\n",
    "  Hk[:,:,i]=(I-rhok[i]*sk*transpose(yk[:,i]))*Hk[:,:,i-1]*(I-rhok[i]*yk[:,i]*transpose(sk))+rhok[i]*sk*transpose(sk)\n",
    "  end\n",
    "  k = 0\n",
    "  verbose && @printf \"%2s %9s %9s\\n\" \"k\" \"fk\" \"||∇f(x)||\"\n",
    "  verbose && @printf \"%2d %9.2e %9.1e\\n\" k fk gnorm\n",
    "  while gnorm > 1.0e-6 + 1.0e-6 * gnorm0 && k < 100 && fk > -1e15\n",
    "    # on prendra la valeur de xk=[0.4 0.4], donc c'est H(5) \n",
    "    Hkk = Hk[:,:,5]\n",
    "    dk = - Hkk*gk\n",
    "    slope = dot(dk, gk)\n",
    "    t = armijo(xk, dk, fk, gk, x -> obj(nlp, x))\n",
    "    xk += t * dk\n",
    "    fk = obj(nlp, xk)\n",
    "    gk = grad(nlp, xk)\n",
    "    gnorm = norm(gk)\n",
    "    k += 1\n",
    "    verbose && @printf \"%2d %9.2e %9.1e %7.1e\\n\" k fk gnorm t\n",
    "  end\n",
    "  return xk\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " k        fk ||∇f(x)||\n",
      " 0  6.08e-01   3.4e+00\n",
      " 1  3.56e-02   7.0e-01 1.0e+00\n",
      " 2  5.99e-03   2.8e-01 1.0e+00\n",
      " 3  1.20e-03   1.2e-01 1.0e+00\n",
      " 4  2.55e-04   5.6e-02 1.0e+00\n",
      " 5  5.58e-05   2.6e-02 1.0e+00\n",
      " 6  1.24e-05   1.2e-02 1.0e+00\n",
      " 7  2.77e-06   5.8e-03 1.0e+00\n",
      " 8  6.19e-07   2.7e-03 1.0e+00\n",
      " 9  1.39e-07   1.3e-03 1.0e+00\n",
      "10  3.11e-08   6.1e-04 1.0e+00\n",
      "11  6.98e-09   2.9e-04 1.0e+00\n",
      "12  1.57e-09   1.4e-04 1.0e+00\n",
      "13  3.51e-10   6.5e-05 1.0e+00\n",
      "14  7.88e-11   3.0e-05 1.0e+00\n",
      "15  7.53e-12   1.2e-05 1.0e+00\n",
      "16 -1.71e-09   2.0e-04 1.0e+00\n",
      "17 -2.90e-07   2.6e-03 1.0e+00\n",
      "18 -4.92e-05   3.4e-02 1.0e+00\n",
      "19 -8.64e-03   4.7e-01 1.0e+00\n",
      "20 -2.30e+00   1.0e+01 1.0e+00\n",
      "21 -8.25e+03   2.2e+03 1.0e+00\n",
      "22 -6.00e+10   8.2e+07 1.0e+00\n",
      "23 -3.11e+24   1.1e+17 1.0e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " -1.158144643028232e8\n",
       "  6.472267542659859e-9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test\n",
    "f(x) = x[1]^2 * (2*x[1] - 3) - 6*x[1]*x[2] * (x[1] - x[2] - 1)\n",
    "nlp = ADNLPModel(f, zeros(2))\n",
    "bfgs_quasi_newton_armijo(nlp, [0.4,0.4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4: application à un problème de grande taille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va ajouter le package `OptimizationProblems` qui contient, comme son nom l'indique, une collection de problème d'optimisation disponible au format de `JuMP` (dans le sous-module `OptimizationProblems.PureJuMP`) et de `ADNLPModel` (dans le sous-module `OptimizationProblems.ADNLPProblems`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ADNLPModels, OptimizationProblems.ADNLPProblems # Attention si vous ne faites pas using ADNLPModels avant ça ne fonctionne pas!\n",
    "using OptimizationProblems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le problème genrose est sans contrainte : true\n",
      "Informations sur le problème genrose :"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dict{Symbol, Any}("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":has_equalities_only => false, :origin => :unknown, :has_inequalities_only => false, :defined_everywhere => missing, :has_fixed_variables => false, :variable_ncon => false, :nvar => 100, :is_feasible => true, :minimize => true, :ncon => 0, :name => \"genrose\", :best_known_lower_bound => -Inf, :objtype => :other, :best_known_upper_bound => 405.1064193957891, :has_bounds => false, :variable_nvar => true, :contype => :unconstrained)\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.14.14, running with linear solver MUMPS 5.6.2.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        3\n",
      "\n",
      "Total number of variables............................:      500\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  0.0000000e+00 0.00e+00 0.00e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "\n",
      "Number of Iterations....: 0\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Dual infeasibility......:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 1\n",
      "Number of objective gradient evaluations             = 1\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 0\n",
      "Total seconds in IPOPT                               = 0.002\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "Solution du problème genrose :"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Use previous functions to solve genrose.\n",
    "\n",
    "# Générer le problème genrose\n",
    "n = 500\n",
    "model = genrose(n=n)\n",
    "\n",
    "# Vérifier s'il est sans contrainte\n",
    "is_unconstrained = unconstrained(model)\n",
    "\n",
    "# Afficher le résultat\n",
    "println(\"Le problème genrose est sans contrainte : \", is_unconstrained)\n",
    "\n",
    "# Accéder aux informations sur le problème en utilisant son meta\n",
    "meta = OptimizationProblems.genrose_meta\n",
    "println(\"Informations sur le problème genrose :\")\n",
    "println(meta)\n",
    "f(x) = x[1]^2 * (2*x[1] - 3) - 6*x[1]*x[2] * (x[1] - x[2] - 1)\n",
    "# Résoudre le problème genrose\n",
    "m = Model(Ipopt.Optimizer)\n",
    "@variable(m, x[1:n])\n",
    "@NLobjective(m, Min, x[1]^2 * (2*x[1] - 3) - 6*x[1]*x[2] * (x[1] - x[2] - 1))\n",
    "\n",
    "optimize!(m)\n",
    "\n",
    "# Afficher la solution\n",
    "println(\"Solution du problème genrose :\")\n",
    "println(value.(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
